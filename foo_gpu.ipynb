{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit238183a89ccd4c25acc508071275f29e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(4.4, shape=(), dtype=float32)\ntf.Tensor(4.8, shape=(), dtype=float32)\ntf.Tensor(4.0, shape=(), dtype=float32)\n"
    }
   ],
   "source": [
    "def foo2(x, y):\n",
    "    a = x * x\n",
    "    b = x * x * x\n",
    "    \n",
    "    return y * b + (1 - y) * a\n",
    "\n",
    "x = tf.Variable(2.0)\n",
    "y = tf.Variable(0.1)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = foo2(x, y)\n",
    "\n",
    "print(z)\n",
    "print(tape.gradient(z, x))\n",
    "print(tape.gradient(z, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(4.0, shape=(), dtype=float32)\ntf.Tensor(1.0, shape=(), dtype=float32)\n"
    }
   ],
   "source": [
    "@tf.custom_gradient\n",
    "def foo(x, y):\n",
    "    def grad(g):\n",
    "        if y > 0.5:\n",
    "            dy_dx = 2 * x\n",
    "        else:\n",
    "            dy_dx = 3 * x * x\n",
    "\n",
    "        return dy_dx * g, g\n",
    "    if y > 0.5:\n",
    "        return x * x, grad\n",
    "    else:\n",
    "        return x * x * x, grad\n",
    "\n",
    "x = tf.Variable(2.0)\n",
    "y = tf.Variable(0.6)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = foo(x, y)\n",
    "\n",
    "print(tape.gradient(z, x))\n",
    "print(tape.gradient(z, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.99996841 3.16217775e-05]\n[0.999683917 0.000316127785]\n[0.5 0.5]\n[0.787298381 0.212701619]\n[0.666666687 0.333333343]\n--------------------------------------------------------------------------------\n[[0.75 0.25]\n [0.875 0.125]\n [0.5 0.5]\n [0.99996841 3.16217775e-05]]\n[[0.03125 -0.09375]\n [0.0117187509 -0.08203125]\n [0 0]\n [3.15904617e-05 -0]]\n"
    }
   ],
   "source": [
    "def to_prob_dist(v):\n",
    "    v2 = tf.sqrt(tf.square(v)+1e-9)\n",
    "    m = tf.expand_dims(tf.reduce_sum(v2, axis=-1),-1)\n",
    "    n = tf.math.divide_no_nan(v2, m)\n",
    "    return n\n",
    "\n",
    "tf.print(to_prob_dist([1.0, 0.0]))\n",
    "tf.print(to_prob_dist([0.1, 0.0]))\n",
    "tf.print(to_prob_dist([0.1, 0.1]))\n",
    "tf.print(to_prob_dist([78.1, 21.1]))\n",
    "tf.print(to_prob_dist([2.0, 1.0]))\n",
    "x = tf.Variable([\n",
    "        [3.0, 1.0],\n",
    "        [7.0, 1.0],\n",
    "        [1.0, 1.0],\n",
    "        [1.0, 0.0],\n",
    "    ])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = to_prob_dist(x)\n",
    "    loss = tf.nn.l2_loss(z)\n",
    "print('-'*80)\n",
    "tf.print(z)\n",
    "tf.print(tape.gradient(loss, x))\n",
    "# tf.print(tape.gradient(z, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3 2\ntf.Tensor(2.0, shape=(), dtype=float32)\ntf.Tensor(0.0, shape=(), dtype=float32)\ntf.Tensor([ 4. -4.], shape=(2,), dtype=float32)\n"
    }
   ],
   "source": [
    "def foo3(x, y, op):\n",
    "    a = x + y\n",
    "    b = x - y\n",
    "\n",
    "    op = to_prob_dist(op)\n",
    "    res = tf.stack([a, b])\n",
    "    c = tf.tensordot(res, op, 1)\n",
    "\n",
    "    return c\n",
    "\n",
    "x = tf.Variable(3.0)\n",
    "y = tf.Variable(2.0)\n",
    "op = tf.Variable([0.5, 0.5])\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = foo3(x, y, op)\n",
    "    loss = tf.nn.l2_loss(z - 1.0)\n",
    "\n",
    "tf.print(z, loss)\n",
    "print(tape.gradient(loss, x))\n",
    "print(tape.gradient(loss, y))\n",
    "print(tape.gradient(loss, op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.888889074 2.86666656 [0.190348491 0.809651494] 2.04444456 2.33333349\n7.91234197e-05 2.8198216 [0.061551623 0.93844837] 2.06532216 0.98742038\n5.19137373e-08 2.81931663 [0.0597037375 0.940296173] 2.06576061 0.999677777\n3.18962634e-11 2.81930351 [0.0596566834 0.94034338] 2.06577229 0.999992\n0 2.81930351 [0.059655454 0.940344572] 2.06577277 1\n0 2.81930351 [0.059655454 0.940344572] 2.06577277 1\n0 2.81930351 [0.059655454 0.940344572] 2.06577277 1\n0 2.81930351 [0.059655454 0.940344572] 2.06577277 1\n0 2.81930351 [0.059655454 0.940344572] 2.06577277 1\n0 2.81930351 [0.059655454 0.940344572] 2.06577277 1\n"
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.SGD(1e-1)\n",
    "# opt = tf.keras.optimizers.Adam(3e-4)\n",
    "target = tf.constant(1.0)\n",
    "\n",
    "x = tf.Variable(3.0)\n",
    "y = tf.Variable(2.0)\n",
    "op = tf.Variable([0.5, 1.0])\n",
    "\n",
    "for i in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        z = foo3(x, y, op)\n",
    "        loss = tf.nn.l2_loss(z - target)\n",
    "    variables = [x, y, op]\n",
    "    grads = tape.gradient(loss,variables)\n",
    "    opt.apply_gradients(zip(grads, variables))\n",
    "\n",
    "    op.assign(to_prob_dist(op))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        tf.print(loss, x, op, y, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-0.999747097 1.99949408\ntf.Tensor(\n[[-0.00025272  0.        ]\n [-0.          0.00037956]], shape=(2, 2), dtype=float32)\ntf.Tensor([-0.          0.00037932], shape=(2,), dtype=float32)\n"
    }
   ],
   "source": [
    "def foo5(v, s, op):\n",
    "    # s = tf.nn.softmax(s)\n",
    "    # op = tf.nn.softmax(op)\n",
    "    s = to_prob_dist(s)\n",
    "    op = to_prob_dist(op)\n",
    "\n",
    "    xy = tf.tensordot(v, s, 1)\n",
    "    x = xy[0]\n",
    "    y = xy[1]\n",
    "\n",
    "    a = x + y\n",
    "    b = x - y\n",
    "    res = tf.stack([a, b])\n",
    "    c = tf.tensordot(res, op, 1)\n",
    "\n",
    "    return c\n",
    "\n",
    "v = tf.constant([2.0, 3.0])\n",
    "s = tf.Variable([\n",
    "    [1.0, 0.0],\n",
    "    [0.0, 1.0],\n",
    "])\n",
    "op = tf.Variable([0.0, 1.0])\n",
    "target = tf.constant(1.0)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = foo5(v, s, op)\n",
    "    loss = tf.nn.l2_loss(z - target)\n",
    "\n",
    "tf.print(z, loss)\n",
    "# print(tape.gradient(z, s))\n",
    "print(tape.gradient(loss, s))\n",
    "print(tape.gradient(loss, op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}