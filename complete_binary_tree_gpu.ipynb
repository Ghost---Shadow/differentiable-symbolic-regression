{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit238183a89ccd4c25acc508071275f29e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from library.array_ops import asymmetrical_vectored_lookup as lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'(((x_0 + x_1) + (x_2 - x_3)) + ((x_4 * x_5) - (x_6 / x_7)))'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "def pretty_print_guess_tensor(const_guess, operand_guess, operator_guess):\n",
    "    # TODO: const_guess\n",
    "\n",
    "    s = []\n",
    "\n",
    "    for t in operand_guess:\n",
    "        s += [f'x_{tf.argmax(t)}']\n",
    "\n",
    "    operator_lookup = ['+','-', '*','/']\n",
    "    result = s[::]\n",
    "    for i, op_one_hot in enumerate(operator_guess):\n",
    "        operators = tf.argmax(op_one_hot,axis=-1)\n",
    "        left = result[::2]\n",
    "        right = (result[1:] + result[:1])[::2]\n",
    "        ops = operators[:len(left)]\n",
    "        result = []\n",
    "        for l, op, r in zip(left, ops, right):\n",
    "            result += [f'({l} {operator_lookup[op]} {r})']\n",
    "\n",
    "\n",
    "    return ' '.join(result)\n",
    "\n",
    "NUM_LEAVES = 8\n",
    "NUM_OPERATORS = 4\n",
    "v1 = tf.range(NUM_LEAVES)\n",
    "v2 = tf.range(NUM_OPERATORS)\n",
    "\n",
    "cgv = tf.one_hot(v1 // 2, NUM_LEAVES//2, dtype=tf.float32)\n",
    "const_guess = tf.concat([cgv, cgv],axis=1)\n",
    "operand_guess = tf.one_hot(v1, NUM_LEAVES, dtype=tf.float32)\n",
    "ogv = tf.expand_dims(tf.one_hot(v2, NUM_OPERATORS, dtype=tf.float32), axis=0)\n",
    "operator_guess = tf.concat([ogv,ogv,ogv], axis=0)\n",
    "\n",
    "pretty_print_guess_tensor(const_guess, operand_guess, operator_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]]\n[[0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]]\n"
    }
   ],
   "source": [
    "@tf.function\n",
    "def to_prob_dist_all(v):\n",
    "    v2 = tf.sqrt(tf.square(v)+1e-9)\n",
    "    # v2 = tf.sqrt(tf.square(v))\n",
    "    m = tf.expand_dims(tf.reduce_sum(v2, axis=-1),-1)\n",
    "    n = tf.math.divide_no_nan(v2, m)\n",
    "    return n\n",
    "\n",
    "tf.print(tf.argmax(operator_guess))\n",
    "tf.print(tf.argmax(to_prob_dist_all(operator_guess)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[-0 1 0.811278105]\n[[-1.44269502 29.8973541]\n [-0.442695022 -0.442695022]\n [-1.02765751 0.557305]]\n"
    }
   ],
   "source": [
    "@tf.function\n",
    "def cross_entropy(x, y, epsilon = 1e-9):\n",
    "    return -2 * tf.reduce_mean(y * tf.math.log(x + epsilon), -1) / tf.math.log(2.)\n",
    "\n",
    "x = tf.constant([\n",
    "    [1.0,0],\n",
    "    [0.5,0.5],\n",
    "    [.75,.25]\n",
    "    ]\n",
    ",dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = cross_entropy(x, x)\n",
    "\n",
    "tf.print(y)\n",
    "tf.print(tape.gradient(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def entropy(x):\n",
    "    return cross_entropy(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([12, 27])>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "@tf.function\n",
    "def dot(x, y):\n",
    "    r = tf.multiply(x, y)\n",
    "    return tf.reduce_sum(r, -1)\n",
    "\n",
    "x = tf.constant([\n",
    "    [2,2,2],\n",
    "    [3,3,3]\n",
    "])\n",
    "\n",
    "dot(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-5 5 5 5]\n [1 1 -1 1]]\n"
    }
   ],
   "source": [
    "@tf.function\n",
    "@tf.custom_gradient\n",
    "def asymmetrical_vectored_lookup(v, k):\n",
    "    k_shape = tf.shape(k)\n",
    "\n",
    "    # Pick the value at the most likely index, non-differentiably\n",
    "    b_idx = tf.argmax(k, axis=-1)\n",
    "    idx_len = tf.shape(b_idx)[0]\n",
    "    a_idx = tf.range(idx_len, dtype=tf.int64)\n",
    "    idx = tf.stack([a_idx, b_idx], axis=1)\n",
    "    forward_result = tf.gather_nd(v, idx)\n",
    "\n",
    "    def grad(upstream_grads):\n",
    "        # Estimate the target scalar which we want to look up\n",
    "        target = forward_result - upstream_grads\n",
    "        target = tf.expand_dims(target, -1)\n",
    "\n",
    "        # Find the index of element in the array which is closest to target\n",
    "        diff_vector = tf.math.squared_difference(v, target)\n",
    "        d_idx = tf.argmin(diff_vector, axis=-1)\n",
    "\n",
    "        # Create a vector which is 1 everywhere except the idx\n",
    "        # of the target, where it is -1\n",
    "        ones = tf.ones(k_shape)\n",
    "        eyes = tf.one_hot([d_idx], k_shape[-1])[0]\n",
    "        k_grad = -(2 * eyes - ones)\n",
    "\n",
    "        # d/dv (v . k) = k\n",
    "        v_grad = k\n",
    "\n",
    "        upstream_grads = tf.expand_dims(upstream_grads, -1)\n",
    "        return upstream_grads * v_grad, tf.math.abs(upstream_grads) * k_grad\n",
    "\n",
    "    return forward_result, grad\n",
    "\n",
    "v = tf.constant([\n",
    "    [7, -1, 12, 0.75],\n",
    "    [1, 2, 3, 4],\n",
    "],dtype=tf.float32)\n",
    "k = tf.constant([\n",
    "    [0,0.5,0.6,0],\n",
    "    [0,0,0,1],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "target = tf.constant([7, 3],dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(k)\n",
    "    tape.watch(v)\n",
    "    result = asymmetrical_vectored_lookup(v, k)\n",
    "    loss = tf.nn.l2_loss(result - target)\n",
    "\n",
    "# tf.print(result)\n",
    "tf.print(tape.gradient(loss, k))\n",
    "# tf.print(tape.gradient(loss, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(8,), dtype=float32, numpy=array([6., 6., 6., 6., 6., 6., 6., 6.], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "@tf.function\n",
    "def resolve_values(const_guess, values, operand_guess):\n",
    "    # TODO: const_guess\n",
    "\n",
    "    operand_guess = to_prob_dist_all(operand_guess)\n",
    "\n",
    "    operand_count = tf.shape(operand_guess)[0]\n",
    "    values = tf.expand_dims(values, axis=0)\n",
    "    values = tf.tile(values, [operand_count,1])\n",
    "\n",
    "    result = asymmetrical_vectored_lookup(values, operand_guess)\n",
    "\n",
    "    return result\n",
    "\n",
    "v1 = tf.range(NUM_LEAVES)\n",
    "cgv = tf.one_hot(v1 // 2, NUM_LEAVES//2, dtype=tf.float32)\n",
    "const_guess = tf.concat([cgv, cgv],axis=1)\n",
    "# operand_guess = tf.one_hot(v1, NUM_LEAVES, dtype=tf.float32)\n",
    "operand_guess = tf.constant([\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "])\n",
    "operand_guess = tf.Variable(operand_guess)\n",
    "# operand_guess = tf.Variable([\n",
    "#     0,0.5,0.5,0, 0,0,0,0,\n",
    "# ],dtype=tf.float32)\n",
    "values = tf.cast(v1,dtype=tf.float32) + 1.0\n",
    "\n",
    "target = tf.ones((NUM_LEAVES,), dtype=tf.float32) * 2.0\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(3e-4)\n",
    "resolve_values(const_guess, values, operand_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "7100 [60 60 60 ... 60 60 60] [0 0 0 ... 100 0 0]\n0 [10 10 10 ... 30 20 20] [79 2 2 ... 8 2 2]\n0 [10 10 10 ... 30 20 20] [94 1 1 ... 0 1 1]\n0 [10 10 10 ... 30 20 20] [97 0 0 ... 0 0 0]\n0 [10 10 10 ... 30 20 20] [99 0 0 ... 0 0 0]\n0 [10 10 10 ... 30 20 20] [99 0 0 ... 0 0 0]\n0 [10 10 10 ... 30 20 20] [100 0 0 ... 0 0 0]\n0 [10 10 10 ... 30 20 20] [100 0 0 ... 0 0 0]\n0 [10 10 10 ... 30 20 20] [100 0 0 ... 0 0 0]\n0 [10 10 10 ... 30 20 20] [100 0 0 ... 0 0 0]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[100,   0,   0,   0,   0,   0,   0,   0],\n       [100,   0,   0,   0,   0,   0,   0,   0],\n       [100,   0,   0,   0,   0,   0,   0,   0],\n       [100,   0,   0,   0,   0,   0,   0,   0],\n       [  0,   0,   0,   0, 100,   0,   0,   0],\n       [  0,   0, 100,   0,   0,   0,   0,   0],\n       [  0, 100,   0,   0,   0,   0,   0,   0],\n       [  0, 100,   0,   0,   0,   0,   0,   0]])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "operand_guess = tf.constant([\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "       [ 0,  0,  0,  0,  0, 1.0, 0, 0],\n",
    "], dtype=tf.float32)\n",
    "operand_guess = tf.Variable(operand_guess)\n",
    "values = tf.constant([10, 20, 30, 40,  50, 60, 70, 80], dtype=tf.float32)\n",
    "\n",
    "target = tf.constant([10, 10, 10, 10,  50, 30, 20, 20], dtype=tf.float32)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=1e-1,\n",
    "    staircase=True)\n",
    "opt = tf.keras.optimizers.Adam(lr_schedule)\n",
    "\n",
    "steps = 100\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        resolved = resolve_values(const_guess, values, operand_guess)\n",
    "\n",
    "        target_loss = tf.nn.l2_loss(resolved - target)\n",
    "        # entropy_loss = entropy(operand_guess)\n",
    "\n",
    "        loss = target_loss # + entropy_loss * 0\n",
    "    \n",
    "    variables = [operand_guess]\n",
    "    grads = tape.gradient(loss, variables)\n",
    "    opt.apply_gradients(zip(grads, variables))\n",
    "\n",
    "    operand_guess.assign(to_prob_dist_all(operand_guess))\n",
    "\n",
    "    if i % (steps // 10) == 0:\n",
    "        dist = tf.round(operand_guess * 100)\n",
    "        tf.print(loss, resolved, dist[0])\n",
    "\n",
    "np.vstack(tf.round(operand_guess * 100).numpy().astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\narray([[ -2.5,   2.5,   2.5,   2.5],\n       [ -5. ,   5. ,   5. ,   5. ],\n       [ 31. ,  31. , -31. ,  31. ],\n       [ -0. ,   0. ,   0. ,   0. ]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "@tf.function\n",
    "def operate(operands, operators):\n",
    "    left = operands[::2]\n",
    "    right = tf.roll(operands, shift=-1, axis=0)[::2]\n",
    "\n",
    "    r_add = left + right\n",
    "    r_sub = left - right\n",
    "    r_mul = left * right\n",
    "    r_div = tf.math.divide_no_nan(left, right)\n",
    "\n",
    "    r = tf.stack([r_add, r_sub, r_mul, r_div], axis=1)\n",
    "\n",
    "    # operators = tf.nn.softmax(operators, axis=-1)\n",
    "    # operators = to_prob_dist_all(operators)\n",
    "\n",
    "    result = asymmetrical_vectored_lookup(r, operators)\n",
    "\n",
    "    return result\n",
    "\n",
    "# operands = tf.range(NUM_LEAVES, dtype=tf.float32)\n",
    "operands = tf.constant([1,2, 3,4, 5,6, 7,8], tf.float32)\n",
    "# v2 = tf.range(NUM_OPERATORS)\n",
    "# operators = tf.constant([\n",
    "#     [1,0,0,0],\n",
    "#     [0,1,0,0],\n",
    "#     [0,0,1,0],\n",
    "#     [0,0,0,1],\n",
    "# ],dtype=tf.float32)\n",
    "operators = tf.constant([\n",
    "    [0,0,0,1],\n",
    "    [0,0,1,0],\n",
    "    [0,1,0,0],\n",
    "    [1,0,0,0],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "operands = tf.Variable(operands)\n",
    "operators = tf.Variable(operators)\n",
    "target = tf.constant([1 + 2, 3 + 4, 5 * 6, 7 + 8],dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    result = operate(operands, operators)\n",
    "    loss = tf.nn.l2_loss(result - target)\n",
    "\n",
    "tape.gradient(loss, operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "667.882813 -0 [0.5 12 -1 15] [3 2 1 0]\n0 0.00480556 [3 -1 30 0.875] [0 1 2 3]\n0 0.0249008518 [3 -1 30 0.875] [0 1 2 3]\n0 0.0337869972 [3 -1 30 0.875] [0 1 2 3]\n0 0.0403830074 [3 -1 30 0.875] [0 1 2 3]\n0 0.0458208323 [3 -1 30 0.875] [0 1 2 3]\n0 0.0505302586 [3 -1 30 0.875] [0 1 2 3]\n0 0.054729566 [3 -1 30 0.875] [0 1 2 3]\n0 0.0585467 [3 -1 30 0.875] [0 1 2 3]\n0 0.0620633774 [3 -1 30 0.875] [0 1 2 3]\n"
    }
   ],
   "source": [
    "operands = tf.constant([1,2, 3,4, 5,6, 7,8], tf.float32)\n",
    "v2 = tf.range(NUM_OPERATORS)\n",
    "# operators = tf.constant([\n",
    "#     [1,0,0,0],\n",
    "#     [0,1,0,0],\n",
    "#     [0,0,1,0],\n",
    "#     [0,0,0,1],\n",
    "# ],dtype=tf.float32)\n",
    "\n",
    "operators = tf.constant([\n",
    "    [0,0,0,1],\n",
    "    [0,0,1,0],\n",
    "    [0,1,0,0],\n",
    "    [1,0,0,0],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "operands = tf.Variable(operands)\n",
    "operators = tf.Variable(operators)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=1e-1,\n",
    "    staircase=True)\n",
    "opt = tf.keras.optimizers.Adam(lr_schedule)\n",
    "\n",
    "target = tf.constant([1 + 2, 3 - 4, 5 * 6, 7 / 8],dtype=tf.float32)\n",
    "\n",
    "@tf.function\n",
    "def operate_train_step(operands, operators, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        result = operate(operands, operators)\n",
    "        target_loss = tf.nn.l2_loss(target - result)\n",
    "\n",
    "        entropy_loss = tf.reduce_sum(entropy(operators))\n",
    "\n",
    "        loss = target_loss + entropy_loss * 0.\n",
    "\n",
    "    variables = [operators]\n",
    "    grads = tape.gradient(loss, variables)\n",
    "\n",
    "    opt.apply_gradients(zip(grads, variables))\n",
    "    operators.assign(to_prob_dist_all(operators))\n",
    "\n",
    "    return loss, target_loss, entropy_loss, result\n",
    "\n",
    "steps = 1000\n",
    "for i in range(steps):\n",
    "    loss, target_loss, entropy_loss, result = operate_train_step(operands, operators, target)\n",
    "\n",
    "    if i % (steps // 10) == 0:\n",
    "        tf.print(target_loss, entropy_loss, result, tf.argmax(operators, axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(((x_0 + x_1) + (x_2 - x_3)) + ((x_4 * x_5) - (x_6 / x_7)))\n19.142857142857142\n[19.1428566]\n[[1 1 1 -1]\n [5 4 -0.142857149 0.122448981]]\n[[[1 1 -1 1]\n  [1 -1 1 1]\n  [1 1 -1 1]\n  [1 1 1 -1]]\n\n [[1 1 -1 1]\n  [1 -1 1 1]\n  [0 0 0 0]\n  [0 0 0 0]]\n\n [[-1 1 1 1]\n  [0 0 0 0]\n  [0 0 0 0]\n  [0 0 0 0]]]\n"
    }
   ],
   "source": [
    "def eager_process_block(operands, operators_arr):\n",
    "    acc = operands\n",
    "\n",
    "    for operators in operators_arr:\n",
    "        num_operands = tf.shape(acc)[0]\n",
    "        operators = operators[:num_operands // 2]\n",
    "        acc = operate(acc, operators)\n",
    "\n",
    "    return acc\n",
    "\n",
    "NUM_LEAVES = 8\n",
    "NUM_OPERATORS = 4\n",
    "v1 = tf.range(NUM_LEAVES)\n",
    "v2 = tf.range(NUM_OPERATORS)\n",
    "\n",
    "cgv = tf.one_hot(v1 // 2, NUM_LEAVES//2, dtype=tf.float32)\n",
    "const_guess = tf.concat([cgv, cgv],axis=1)\n",
    "operand_guess = tf.one_hot(v1, NUM_LEAVES, dtype=tf.float32)\n",
    "ogv = tf.expand_dims(tf.one_hot(v2, NUM_OPERATORS, dtype=tf.float32), axis=0)\n",
    "operator_guess = tf.concat([ogv,ogv,ogv], axis=0)\n",
    "values = tf.cast(v1,dtype=tf.float32)\n",
    "operands = resolve_values(const_guess, values, operand_guess)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(operands)\n",
    "    tape.watch(operator_guess)\n",
    "    result = eager_process_block(operands, operator_guess)\n",
    "\n",
    "tf.print(pretty_print_guess_tensor(const_guess, operand_guess, operator_guess))\n",
    "x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7 = list(range(8))\n",
    "tf.print((((x_0 + x_1) + (x_2 - x_3)) + ((x_4 * x_5) - (x_6 / x_7))))\n",
    "tf.print(result)\n",
    "tf.print(tf.reshape(tape.gradient(result, operands),(2,4)))\n",
    "tf.print(tape.gradient(result, operator_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(((x_0 + x_1) + (x_2 - x_3)) + ((x_4 * x_5) - (x_6 / x_7)))\n19.142857142857142\n[19.1428566]\n[[1 1 1 -1]\n [5 4 -0.142857149 0.122448981]]\n[[[1 1 -1 1]\n  [1 -1 1 1]\n  [1 1 -1 1]\n  [1 1 1 -1]]\n\n [[1 1 -1 1]\n  [1 -1 1 1]\n  [0 0 0 0]\n  [0 0 0 0]]\n\n [[-1 1 1 1]\n  [0 0 0 0]\n  [0 0 0 0]\n  [0 0 0 0]]]\n"
    }
   ],
   "source": [
    "@tf.function\n",
    "def unrolled_process_block_3(operands, operators_arr):\n",
    "    acc = operands\n",
    "\n",
    "    # Level 1\n",
    "    operators = operators_arr[0]\n",
    "    operators = operators[:4]\n",
    "    acc = operate(acc, operators)\n",
    "\n",
    "    # Level 2\n",
    "    operators = operators_arr[1]\n",
    "    operators = operators[:2]\n",
    "    acc = operate(acc, operators)\n",
    "\n",
    "    # Level 3\n",
    "    operators = operators_arr[2]\n",
    "    operators = operators[:1]\n",
    "    acc = operate(acc, operators)\n",
    "\n",
    "    return acc\n",
    "\n",
    "NUM_LEAVES = 8\n",
    "NUM_OPERATORS = 4\n",
    "v1 = tf.range(NUM_LEAVES)\n",
    "v2 = tf.range(NUM_OPERATORS)\n",
    "\n",
    "cgv = tf.one_hot(v1 // 2, NUM_LEAVES//2, dtype=tf.float32)\n",
    "const_guess = tf.concat([cgv, cgv],axis=1)\n",
    "operand_guess = tf.one_hot(v1, NUM_LEAVES, dtype=tf.float32)\n",
    "ogv = tf.expand_dims(tf.one_hot(v2, NUM_OPERATORS, dtype=tf.float32), axis=0)\n",
    "operator_guess = tf.concat([ogv,ogv,ogv], axis=0)\n",
    "values = tf.cast(v1,dtype=tf.float32)\n",
    "operands = resolve_values(const_guess, values, operand_guess)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(operands)\n",
    "    tape.watch(operator_guess)\n",
    "    result = unrolled_process_block_3(operands, operator_guess)\n",
    "\n",
    "tf.print(pretty_print_guess_tensor(const_guess, operand_guess, operator_guess))\n",
    "x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7 = list(range(8))\n",
    "tf.print((((x_0 + x_1) + (x_2 - x_3)) + ((x_4 * x_5) - (x_6 / x_7))))\n",
    "tf.print(result)\n",
    "tf.print(tf.reshape(tape.gradient(result, operands),(2,4)))\n",
    "tf.print(tape.gradient(result, operator_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([19.142857], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "def print_collapsed_result(values, const_guess, operand_guess, operator_guess):\n",
    "    # TODO: const_guess\n",
    "\n",
    "    operands = tf.round(operand_guess)\n",
    "    acc = resolve_values(const_guess, values, operands)\n",
    "    operators = tf.round(operator_guess)\n",
    "\n",
    "    result = eager_process_block(acc, operators)\n",
    "\n",
    "    return result\n",
    "\n",
    "NUM_LEAVES = 8\n",
    "NUM_OPERATORS = 4\n",
    "v1 = tf.range(NUM_LEAVES)\n",
    "v2 = tf.range(NUM_OPERATORS)\n",
    "\n",
    "cgv = tf.one_hot(v1 // 2, NUM_LEAVES//2, dtype=tf.float32)\n",
    "const_guess = tf.concat([cgv, cgv],axis=1)\n",
    "operand_guess = tf.one_hot(v1, NUM_LEAVES, dtype=tf.float32)\n",
    "ogv = tf.expand_dims(tf.one_hot(v2, NUM_OPERATORS, dtype=tf.float32), axis=0)\n",
    "operator_guess = tf.concat([ogv,ogv,ogv], axis=0)\n",
    "\n",
    "print_collapsed_result(values, const_guess, operand_guess, operator_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1.66867876, 0.0102040041, 0, 0.00725521892, 0.00932952948)\n[[-0.0836029053 0 0 ... 0 0 0]\n [0 -0.0836029053 0 ... 0 0 0]\n [0 0 -0.0836029053 ... 0 0 0]\n ...\n [0 0 0 ... -0.0834617615 0 0]\n [0 0 0 ... 0 -0.0835266113 0]\n [0 0 0 ... 0 0 -0.0835228]]\n[[[-0.0716552734 0 0 0]\n  [0 -0.0716552734 0 0]\n  [0 0 -0.0716552734 0]\n  [0 0 0 -0.0716552734]]\n\n [[-0.0716552734 0 0 0]\n  [0 -0.0716552734 0 0]\n  [0 0 -0.0716095 0]\n  [0 0 0 -0.0716095]]\n\n [[-0.0716552734 0 0 0]\n  [0 -0.0716095 0 0]\n  [0 0 -0.0716095 0]\n  [0 0 0 -0.0716095]]]\n"
    }
   ],
   "source": [
    "def bind_opt_train_step(opt, entropy_weight=1e+2):\n",
    "    @tf.function\n",
    "    def train_step(const_guess, operand_guess, operator_guess, values, target):\n",
    "        with tf.GradientTape() as tape:\n",
    "            cg, opg, otg = const_guess, operand_guess, operator_guess\n",
    "            # cg = tf.nn.softmax(cg)\n",
    "            # opg = tf.nn.softmax(opg)\n",
    "            # otg = tf.nn.softmax(otg)\n",
    "\n",
    "            cg = to_prob_dist_all(cg)\n",
    "            opg = to_prob_dist_all(opg)\n",
    "            otg = to_prob_dist_all(otg)\n",
    "\n",
    "            cg_entropy = 0.0 # TODO\n",
    "            opg_entropy = tf.reduce_sum(entropy(opg))\n",
    "            otg_entropy = tf.reduce_sum(entropy(otg))\n",
    "\n",
    "            operands = resolve_values(cg, values, opg)\n",
    "            result = unrolled_process_block_3(operands, otg)\n",
    "\n",
    "            target_loss = tf.nn.l2_loss(result[0] - target)\n",
    "\n",
    "            loss = target_loss\n",
    "\n",
    "            if target_loss < 1:\n",
    "                loss += entropy_weight * (opg_entropy + otg_entropy)\n",
    "\n",
    "        variables = [operand_guess, operator_guess]\n",
    "        grads = tape.gradient(loss, variables)\n",
    "        # grads = [tf.clip_by_norm(g, 100.0) for g in grads]\n",
    "        opt.apply_gradients(zip(grads, variables))\n",
    "\n",
    "        const_guess.assign(to_prob_dist_all(const_guess))\n",
    "        operand_guess.assign(to_prob_dist_all(operand_guess))\n",
    "        operator_guess.assign(to_prob_dist_all(operator_guess))\n",
    "\n",
    "        return loss, target_loss, cg_entropy, opg_entropy, otg_entropy\n",
    "\n",
    "    return train_step\n",
    "\n",
    "NUM_LEAVES = 8\n",
    "NUM_OPERATORS = 4\n",
    "v1 = tf.range(NUM_LEAVES)\n",
    "v2 = tf.range(NUM_OPERATORS)\n",
    "\n",
    "cgv = tf.one_hot(v1 // 2, NUM_LEAVES//2, dtype=tf.float32)\n",
    "const_guess = tf.concat([cgv, cgv],axis=1)\n",
    "operand_guess = tf.one_hot(v1, NUM_LEAVES, dtype=tf.float32)\n",
    "ogv = tf.expand_dims(tf.one_hot(v2, NUM_OPERATORS, dtype=tf.float32), axis=0)\n",
    "operator_guess = tf.concat([ogv,ogv,ogv], axis=0)\n",
    "values = tf.cast(v1,dtype=tf.float32)\n",
    "\n",
    "const_guess = tf.Variable(const_guess)\n",
    "operand_guess = tf.Variable(operand_guess)\n",
    "operator_guess = tf.Variable(operator_guess)\n",
    "\n",
    "target = 19.0\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(3e-4)\n",
    "# opt = tf.keras.optimizers.SGD(1e-1)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=1e-1,\n",
    "    staircase=True)\n",
    "opt = tf.keras.optimizers.Adam(lr_schedule)\n",
    "train_step = bind_opt_train_step(opt)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(const_guess)\n",
    "    tape.watch(operand_guess)\n",
    "    tape.watch(operator_guess)\n",
    "\n",
    "    result = train_step(const_guess, operand_guess, operator_guess, values, target)\n",
    "\n",
    "tf.print(result)\n",
    "tf.print(tape.gradient(result, operand_guess))\n",
    "tf.print(tape.gradient(result, operator_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 19.1428566 73.7244797 73.7244797 0 0.00725521892 0.00932952948\n100 7 6.0931325 0 0 1.76757944 4.32555294\n200 7 2.33467197 0 0 0.705791712 1.62888026\n300 7 1.43303084 0 0 0.397692 1.03533888\n400 7 1.2449199 0 0 0.342898875 0.902021\n500 7 1.24905741 0 0 0.347695202 0.90136224\n600 7 1.32254815 0 0 0.379939407 0.942608714\n700 7 1.37132597 0 0 0.401007175 0.970318854\n800 7 1.40732276 0 0 0.416651845 0.990670919\n900 7 1.43638754 0 0 0.429335862 1.00705171\n(((x_0 + x_0) * (x_0 - x_7)) + ((x_0 + x_0) - (x_0 - x_7)))\n"
    }
   ],
   "source": [
    "# opt = tf.keras.optimizers.Adam(3e-4)\n",
    "# opt = tf.keras.optimizers.Adam(1e-2)\n",
    "# opt = tf.keras.optimizers.SGD(1e-1)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=1e-1,\n",
    "    staircase=True)\n",
    "opt = tf.keras.optimizers.Adam(lr_schedule)\n",
    "train_step = bind_opt_train_step(opt, 1)\n",
    "\n",
    "NUM_LEAVES = 8\n",
    "NUM_OPERATORS = 4\n",
    "v1 = tf.range(NUM_LEAVES)\n",
    "v2 = tf.range(NUM_OPERATORS)\n",
    "\n",
    "cgv = tf.one_hot(v1 // 2, NUM_LEAVES//2, dtype=tf.float32)\n",
    "const_guess = tf.concat([cgv, cgv],axis=1)\n",
    "operand_guess = tf.one_hot(v1, NUM_LEAVES, dtype=tf.float32)\n",
    "ogv = tf.expand_dims(tf.one_hot(v2, NUM_OPERATORS, dtype=tf.float32), axis=0)\n",
    "operator_guess = tf.concat([ogv,ogv,ogv], axis=0)\n",
    "values = tf.cast(v1,dtype=tf.float32)\n",
    "\n",
    "const_guess = tf.Variable(const_guess)\n",
    "operand_guess = tf.Variable(operand_guess)\n",
    "operator_guess = tf.Variable(operator_guess)\n",
    "\n",
    "target = 7.0\n",
    "steps = 1000\n",
    "for i in range(steps):\n",
    "    loss, target_loss, cg_entropy, opg_entropy, otg_entropy = train_step(const_guess, operand_guess, operator_guess, values, target)\n",
    "\n",
    "    if i % (steps // 10) == 0:\n",
    "        cg = const_guess.numpy()\n",
    "        opg = operand_guess.numpy()\n",
    "        otg = operator_guess.numpy()\n",
    "        collapsed_result = print_collapsed_result(values, cg, opg, otg)\n",
    "\n",
    "        tf.print(i, collapsed_result[0], loss, target_loss, cg_entropy, opg_entropy, otg_entropy)\n",
    "        # tf.print(pretty_print_guess_tensor(cg, opg, otg))\n",
    "tf.print(pretty_print_guess_tensor(cg, opg, otg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(8, 8), dtype=float32, numpy=\narray([[100.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n       [ 91.,   0.,   0.,   0.,   0.,   0.,   0.,   8.],\n       [100.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 100.],\n       [100.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n       [100.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n       [ 68.,   0.,   0.,   0.,   0.,   0.,   0.,  32.],\n       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 100.]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "tf.round(opg * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 1., 12.,  1.,  1.,  1.,  1., 24.,  1.], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "tf.round(entropy(opg)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}