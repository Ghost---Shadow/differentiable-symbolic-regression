{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit238183a89ccd4c25acc508071275f29e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'(((x_0 + x_1) + (x_2 - x_3)) + ((x_4 * x_5) - (x_6 / x_7)))'"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "def pretty_print_guess_tensor(const_guess, operand_guess, operator_guess):\n",
    "    # TODO: const_guess\n",
    "\n",
    "    s = []\n",
    "\n",
    "    for t in operand_guess:\n",
    "        s += [f'x_{tf.argmax(t)}']\n",
    "\n",
    "    operator_lookup = ['+','-', '*','/']\n",
    "    result = s[::]\n",
    "    for i, op_one_hot in enumerate(operator_guess):\n",
    "        operators = tf.argmax(op_one_hot,axis=-1)\n",
    "        left = result[::2]\n",
    "        right = (result[1:] + result[:1])[::2]\n",
    "        ops = operators[:len(left)]\n",
    "        result = []\n",
    "        for l, op, r in zip(left, ops, right):\n",
    "            result += [f'({l} {operator_lookup[op]} {r})']\n",
    "\n",
    "\n",
    "    return ' '.join(result)\n",
    "\n",
    "NUM_LEAVES = 8\n",
    "NUM_OPERATORS = 4\n",
    "v1 = tf.range(NUM_LEAVES)\n",
    "v2 = tf.range(NUM_OPERATORS)\n",
    "\n",
    "cgv = tf.one_hot(v1 // 2, NUM_LEAVES//2, dtype=tf.float32)\n",
    "const_guess = tf.concat([cgv, cgv],axis=1)\n",
    "operand_guess = tf.one_hot(v1, NUM_LEAVES, dtype=tf.float32)\n",
    "ogv = tf.expand_dims(tf.one_hot(v2, NUM_OPERATORS, dtype=tf.float32), axis=0)\n",
    "operator_guess = tf.concat([ogv,ogv,ogv], axis=0)\n",
    "\n",
    "pretty_print_guess_tensor(const_guess, operand_guess, operator_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n <tf.Tensor: shape=(1, 8, 2), dtype=float32, numpy=\n array([[[1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.]]], dtype=float32)>,\n <tf.Tensor: shape=(1, 3, 4, 4), dtype=float32, numpy=\n array([[[[1., 0., 0., 0.],\n          [0., 1., 0., 0.],\n          [0., 0., 1., 0.],\n          [0., 0., 0., 1.]],\n \n         [[1., 0., 0., 0.],\n          [0., 1., 0., 0.],\n          [0., 0., 1., 0.],\n          [0., 0., 0., 1.]],\n \n         [[1., 0., 0., 0.],\n          [0., 1., 0., 0.],\n          [0., 0., 1., 0.],\n          [0., 0., 0., 1.]]]], dtype=float32)>,\n <tf.Tensor: shape=(1, 3, 2), dtype=float32, numpy=\n array([[[1., 2.],\n         [2., 3.],\n         [4., 5.]]], dtype=float32)>,\n <tf.Tensor: shape=(1, 3, 1), dtype=float32, numpy=\n array([[[3.],\n         [5.],\n         [9.]]], dtype=float32)>)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "def eqn_to_block_tensor(fn, xs, tree_depth=3, num_op_types=4):\n",
    "    NUM_LEAVES = 1 << tree_depth\n",
    "    NUM_VARS = len(xs[0])\n",
    "\n",
    "    target = []\n",
    "    values = []\n",
    "\n",
    "    for x in xs:\n",
    "        values.append(x)\n",
    "        target.append(fn(*x))\n",
    "\n",
    "    operators = []\n",
    "    for _ in range(tree_depth):\n",
    "        operators.append(tf.one_hot(np.arange(NUM_LEAVES // 2) % num_op_types, num_op_types))\n",
    "    operators = tf.stack(operators)\n",
    "\n",
    "    values = tf.constant([values], dtype=tf.float32) # [1, datapoint_x, data_point_dim]\n",
    "    target = tf.expand_dims(tf.constant([target], dtype=tf.float32), -1) # [1, datapoint_y, 1]\n",
    "    operand_guess = tf.one_hot(np.arange(NUM_LEAVES) % NUM_VARS, NUM_VARS) \n",
    "    operand_guess = tf.expand_dims(operand_guess, 0) # [1, NUM_LEAVES, NUM_VARS]\n",
    "    operator_guess = tf.expand_dims(operators, 0) # [1, tree_level, op_pair, op_type_one_hot]\n",
    "    const_guess = tf.constant([1.]) # TODO\n",
    "\n",
    "    return const_guess, operand_guess, operator_guess, values, target\n",
    "\n",
    "fn = lambda x, y: x + y\n",
    "xs = np.array([[1,2], [2,3], [4,5]], dtype=np.float32)\n",
    "\n",
    "eqn_to_block_tensor(fn, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'(((x_0 + x_1) + (x_0 - x_1)) + ((x_0 * x_1) - (x_0 / x_1)))'"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "_, opg, otg, _, _ = eqn_to_block_tensor(fn, xs)\n",
    "\n",
    "pretty_print_guess_tensor(None, opg[0], otg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]]\n[[0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]]\n"
    }
   ],
   "source": [
    "@tf.function\n",
    "def to_prob_dist_all(v):\n",
    "    v2 = tf.sqrt(tf.square(v)+1e-9)\n",
    "    # v2 = tf.sqrt(tf.square(v))\n",
    "    m = tf.expand_dims(tf.reduce_sum(v2, axis=-1),-1)\n",
    "    n = tf.math.divide_no_nan(v2, m)\n",
    "    return n\n",
    "\n",
    "tf.print(tf.argmax(operator_guess))\n",
    "tf.print(tf.argmax(to_prob_dist_all(operator_guess)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[-0 1 0.811278105]\n[[-1.44269502 29.8973541]\n [-0.442695022 -0.442695022]\n [-1.02765751 0.557305]]\n"
    }
   ],
   "source": [
    "@tf.function\n",
    "def cross_entropy(x, y, epsilon = 1e-9):\n",
    "    return -2 * tf.reduce_mean(y * tf.math.log(x + epsilon), -1) / tf.math.log(2.)\n",
    "\n",
    "x = tf.constant([\n",
    "    [1.0,0],\n",
    "    [0.5,0.5],\n",
    "    [.75,.25]\n",
    "    ]\n",
    ",dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = cross_entropy(x, x)\n",
    "\n",
    "tf.print(y)\n",
    "tf.print(tape.gradient(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def entropy(x):\n",
    "    return cross_entropy(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([12, 27])>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "@tf.function\n",
    "def dot(x, y):\n",
    "    r = tf.multiply(x, y)\n",
    "    return tf.reduce_sum(r, -1)\n",
    "\n",
    "x = tf.constant([\n",
    "    [2,2,2],\n",
    "    [3,3,3]\n",
    "])\n",
    "\n",
    "dot(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1 5]\n [7 33]]\n[[[1 -1 1]\n  [-1 1 1]]\n\n [[0 0 0]\n  [1 1 -1]]]\n"
    }
   ],
   "source": [
    "@tf.function\n",
    "@tf.custom_gradient\n",
    "def asymmetrical_vectored_lookup(v, k):\n",
    "    k_shape = tf.shape(k)\n",
    "    v_shape = tf.shape(v)\n",
    "\n",
    "    tf.debugging.assert_equal(k_shape, v_shape)\n",
    "\n",
    "    # Pick the value at the most likely index, non-differentiably\n",
    "    flat_k = tf.reshape(k, [-1, k_shape[-1]])\n",
    "    collapsed_k = tf.argmax(flat_k, -1)\n",
    "    collapsed_k = tf.one_hot(collapsed_k, k_shape[-1])\n",
    "    unflat_k = tf.reshape(collapsed_k, k_shape)\n",
    "    forward_result = dot(v, unflat_k)\n",
    "\n",
    "    def grad(upstream_grads):\n",
    "        # Estimate the target scalar which we want to look up\n",
    "        target = forward_result - upstream_grads\n",
    "        target = tf.expand_dims(target, -1)\n",
    "\n",
    "        # Find the index of element in the array which is closest to target\n",
    "        diff_vector = tf.math.squared_difference(v, target)\n",
    "        d_idx = tf.argmin(diff_vector, axis=-1)\n",
    "\n",
    "        # Create a vector which is 1 everywhere except the idx\n",
    "        # of the target, where it is -1\n",
    "        ones = tf.ones(k_shape)\n",
    "        eyes = tf.one_hot([d_idx], k_shape[-1])[0]\n",
    "        k_grad = -(2 * eyes - ones)\n",
    "\n",
    "        # d/dv (v . k) = k\n",
    "        v_grad = k\n",
    "\n",
    "        upstream_grads = tf.expand_dims(upstream_grads, -1)\n",
    "        return upstream_grads * v_grad, tf.math.abs(upstream_grads) * k_grad\n",
    "\n",
    "    return forward_result, grad\n",
    "\n",
    "v = tf.constant([\n",
    "    [[ 1.,  2.,  3.], [ 4.,  5.,  6.]],\n",
    "    [[ 7.,  8.,  9.], [11., 22., 33.]],\n",
    "]\n",
    ",dtype=tf.float32)\n",
    "\n",
    "k = tf.constant([\n",
    "    [[1., 0., 0.], [0., 1., 0.]],\n",
    "    [[1., 1., 0.], [0., 0., 1.]]\n",
    "],dtype=tf.float32)\n",
    "\n",
    "target = tf.constant([\n",
    "    [2, 4],\n",
    "    [7, 34],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(k)\n",
    "    tape.watch(v)\n",
    "    result = asymmetrical_vectored_lookup(v, k)\n",
    "    loss = tf.nn.l2_loss(result - target)\n",
    "\n",
    "tf.print(result)\n",
    "tf.print(tape.gradient(loss, k))\n",
    "# tf.print(tape.gradient(loss, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[[1 2 3]\n  [4 5 6]]\n\n [[7 9 7]\n  [11 33 11]]]\n[[[-2 2 2]\n  [-2 2 2]\n  [2 -2 2]]\n\n [[-2 2 2]\n  [2 0 0]\n  [-2 2 2]]]\n"
    }
   ],
   "source": [
    "@tf.function\n",
    "def resolve_values(const_guess, values, operand_guess):\n",
    "    # TODO: const_guess\n",
    "\n",
    "    # tf.debugging.assert_rank(const_guess, 3)\n",
    "    tf.debugging.assert_rank(values, 3) # [outer_batch, inner_batch, VALUES_SIZE]\n",
    "    tf.debugging.assert_rank(operand_guess, 3) # [outer_batch, LEAVES_SIZE, VALUES_SIZE]\n",
    "\n",
    "    values_shape = tf.shape(values)\n",
    "    operands_shape = tf.shape(operand_guess)\n",
    "\n",
    "    outer_batch, inner_batch, VALUES_SIZE = [values_shape[0], values_shape[1], values_shape[2]]\n",
    "    outer_batch, LEAVES_SIZE, VALUES_SIZE = [operands_shape[0], operands_shape[1], operands_shape[2]]\n",
    "\n",
    "    # Broadcast the operand choices\n",
    "    operand_guess = tf.expand_dims(operand_guess, axis=1)\n",
    "    operand_guess = tf.tile(operand_guess, [1,inner_batch,1,1]) # [outer_batch, inner_batch, LEAVES_SIZE, VALUES_SIZE]\n",
    "\n",
    "    # Broadcast the values\n",
    "    values = tf.expand_dims(values, axis=2)\n",
    "    values = tf.tile(values, [1, 1, LEAVES_SIZE, 1]) # [outer_batch, inner_batch, LEAVES_SIZE, VALUES_SIZE]\n",
    "\n",
    "    # Dot product\n",
    "    # operand_guess = to_prob_dist_all(operand_guess)\n",
    "    # result = dot(values, operand_guess) # [outer_batch, inner_batch, LEAVES_SIZE]\n",
    "    result = asymmetrical_vectored_lookup(values, operand_guess)\n",
    "\n",
    "    return result\n",
    "\n",
    "# v1 = tf.range(NUM_LEAVES)\n",
    "# cgv = tf.one_hot(v1 // 2, NUM_LEAVES//2, dtype=tf.float32)\n",
    "# const_guess = tf.concat([cgv, cgv],axis=1)\n",
    "\n",
    "operand_guess = tf.Variable([\n",
    "    [[1,0,0], [0,1,0], [0,0,1]],\n",
    "    [[1,1,0], [0,0,1], [1,1,1]],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "values = tf.constant([\n",
    "    [[1,2,3],\n",
    "    [4,5,6]],\n",
    "    [[7,8,9],\n",
    "    [11,22,33]],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    result = resolve_values(const_guess, values, operand_guess)\n",
    "\n",
    "grads = tape.gradient(result, operand_guess)\n",
    "\n",
    "tf.print(tf.round(result))\n",
    "tf.print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "185\n185\n185\n185\n185\n0\n0\n0\n0\n0\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\narray([[[  0.,  12.,  88.],\n        [  0., 100.,   0.],\n        [ 88.,  12.,   0.]],\n\n       [[ 88.,  12.,   0.],\n        [  0.,  12.,  88.],\n        [ 88.,  12.,   0.]]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "operand_guess = tf.Variable([\n",
    "    [[0,1,0], [0,1,0], [0,1,0]],\n",
    "    [[0,1,0], [0,1,0], [0,1,0]],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "values = tf.constant([\n",
    "    [[1,2,3], [4,5,6]],\n",
    "    [[7,8,9], [11,22,33]],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "target = tf.constant([\n",
    "    [[3, 2, 1], [6, 5, 4]],\n",
    "    [[7, 9, 7], [11, 33, 11]],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "operand_guess = tf.Variable(operand_guess)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=1e-1,\n",
    "    staircase=True)\n",
    "opt = tf.keras.optimizers.Adam(lr_schedule)\n",
    "\n",
    "steps = 10\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        resolved = resolve_values(const_guess, values, operand_guess)\n",
    "\n",
    "        target_loss = tf.nn.l2_loss(resolved - target)\n",
    "        # entropy_loss = entropy(operand_guess)\n",
    "\n",
    "        loss = target_loss # + entropy_loss * 0\n",
    "    \n",
    "    variables = [operand_guess]\n",
    "    grads = tape.gradient(loss, variables)\n",
    "    opt.apply_gradients(zip(grads, variables))\n",
    "\n",
    "    operand_guess.assign(to_prob_dist_all(operand_guess))\n",
    "\n",
    "    if i % (steps // 10) == 0:\n",
    "        # dist = tf.round(operand_guess * 100)\n",
    "        tf.print(loss)\n",
    "\n",
    "tf.round(operand_guess * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[[3 -1]\n  [11 -1]]\n\n [[242 0.75]\n  [3630 0.875]]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 4), dtype=float32, numpy=\narray([[[-0.,  0.,  0.,  0.],\n        [ 0., -0.,  0.,  0.]],\n\n       [[ 0.,  0., -0.,  0.],\n        [ 0.,  0.,  0., -0.]]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "@tf.function\n",
    "def operate(operands, operators):\n",
    "    tf.debugging.assert_rank(operands, 3, 'Expected operands to be rank 3. [equation, datapoint, level]')\n",
    "    tf.debugging.assert_rank(operators, 3, 'Expected operators to be rank 3. [equation, op_pair, op_type_one_hot]')\n",
    "\n",
    "    opd_shape = tf.shape(operands)\n",
    "    tf.debugging.assert_equal(opd_shape[-1] % 2, 0, 'Shape of axis -1 of operands must be div by 2')\n",
    "\n",
    "    left = operands[:, :, ::2]\n",
    "    right = tf.roll(operands, shift=-1, axis=-1)[:, :, ::2]\n",
    "\n",
    "    r_add = left + right\n",
    "    r_sub = left - right\n",
    "    r_mul = left * right\n",
    "    r_div = tf.math.divide_no_nan(left, right)\n",
    "\n",
    "    r = tf.stack([r_add, r_sub, r_mul, r_div], axis=-1) # [equation, datapoint, op_pair, op_type_one_hot]\n",
    "\n",
    "    opt = tf.expand_dims(operators, axis=1)\n",
    "    opt = tf.tile(opt, [1, opd_shape[1], 1, 1]) # [equation, datapoint, op_pair, op_type_one_hot]\n",
    "\n",
    "    # operators = tf.nn.softmax(operators, axis=-1)\n",
    "    # operators = to_prob_dist_all(operators)\n",
    "\n",
    "    result = asymmetrical_vectored_lookup(r, opt) # [equation, datapoint, op_pair]\n",
    "\n",
    "    return result\n",
    "\n",
    "operands = tf.constant([\n",
    "    [[1, 2, 3, 4], [5, 6, 7, 8]],\n",
    "    [[11, 22, 33, 44], [55, 66, 77, 88]],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "add = [1,0,0,0]\n",
    "sub = [0,1,0,0]\n",
    "mul = [0,0,1,0]\n",
    "div = [0,0,0,1]\n",
    "\n",
    "operators = tf.constant([\n",
    "    [add, sub],\n",
    "    [mul, div]\n",
    "],dtype=tf.float32)\n",
    "\n",
    "operands = tf.Variable(operands)\n",
    "operators = tf.Variable(operators)\n",
    "target = tf.constant([\n",
    "    [[1 + 2, 3 - 4], [5 + 6, 7 - 8]],\n",
    "    [[11 * 22, 33 / 44], [55 * 66, 77 / 88]],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    result = operate(operands, operators)\n",
    "    loss = tf.nn.l2_loss(result - target)\n",
    "\n",
    "tf.print(result)\n",
    "tape.gradient(loss, operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6194916.5\n6194916.5\n6194916.5\n6194916.5\n6194916.5\n0\n0\n0\n0\n0\n[[[100 0 0 0]\n  [8 89 1 1]]\n\n [[8 1 89 1]\n  [8 1 1 89]]]\n"
    }
   ],
   "source": [
    "operands = tf.constant([\n",
    "    [[1, 2, 3, 4], [5, 6, 7, 8]],\n",
    "    [[11, 22, 33, 44], [55, 66, 77, 88]],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "add = [1,0,0,0]\n",
    "sub = [1,0,0,0]\n",
    "mul = [1,0,0,0]\n",
    "div = [1,0,0,0]\n",
    "\n",
    "operators = tf.constant([\n",
    "    [add, sub],\n",
    "    [mul, div]\n",
    "],dtype=tf.float32)\n",
    "\n",
    "operands = tf.Variable(operands)\n",
    "operators = tf.Variable(operators)\n",
    "target = tf.constant([\n",
    "    [[1 + 2, 3 - 4], [5 + 6, 7 - 8]],\n",
    "    [[11 * 22, 33 / 44], [55 * 66, 77 / 88]],\n",
    "],dtype=tf.float32)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=1e-1,\n",
    "    staircase=True)\n",
    "opt = tf.keras.optimizers.Adam(lr_schedule)\n",
    "\n",
    "steps = 10\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        result = operate(operands, operators)\n",
    "        target_loss = tf.nn.l2_loss(target - result)\n",
    "\n",
    "        # entropy_loss = tf.reduce_sum(entropy(operators))\n",
    "\n",
    "        loss = target_loss # + entropy_loss * 0.\n",
    "\n",
    "    variables = [operators]\n",
    "    grads = tape.gradient(loss, variables)\n",
    "\n",
    "    opt.apply_gradients(zip(grads, variables))\n",
    "    operators.assign(to_prob_dist_all(operators))\n",
    "\n",
    "    if i % (steps // 10) == 0:\n",
    "        tf.print(loss)\n",
    "\n",
    "tf.print(tf.round(operators * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(((x_0 + x_1) + (x_0 - x_1)) + ((x_0 * x_1) - (x_0 / x_1)))\n3.5\n[[[3.5]\n  [9.33333397]\n  [27.2]]\n\n [[3.5]\n  [9.33333397]\n  [27.2]]]\n[[[[-1 3 1 3]\n   [3 -3 3 3]\n   [1 3 1 1]\n   [3 3 1 -1]]\n\n  [[-3 3 3 3]\n   [3 1 -1 3]\n   [0 0 0 0]\n   [0 0 0 0]]\n\n  [[-1 3 1 3]\n   [0 0 0 0]\n   [0 0 0 0]\n   [0 0 0 0]]]\n\n\n [[[-1 3 1 3]\n   [3 -3 3 3]\n   [1 3 1 1]\n   [3 3 1 -1]]\n\n  [[-3 3 3 3]\n   [3 1 -1 3]\n   [0 0 0 0]\n   [0 0 0 0]]\n\n  [[-1 3 1 3]\n   [0 0 0 0]\n   [0 0 0 0]\n   [0 0 0 0]]]]\n"
    }
   ],
   "source": [
    "def eager_process_block(operands, operators_arr):\n",
    "    acc = operands\n",
    "\n",
    "    levels = tf.shape(operators_arr)[1]\n",
    "\n",
    "    for level in tf.range(levels):\n",
    "        num_operands = tf.shape(acc)[-1]\n",
    "        op = operators_arr[:, level, :num_operands // 2, :]\n",
    "        acc = operate(acc, op)\n",
    "\n",
    "    return acc\n",
    "\n",
    "fn1 = lambda x, y: x + y\n",
    "fn2 = lambda x, y: x - y\n",
    "xs1 = np.array([[1,2], [2,3], [4,5]], dtype=np.float32)\n",
    "xs2 = np.array([[1,2], [2,3], [4,5]], dtype=np.float32)\n",
    "\n",
    "cg1, og1, ot1, v1, t1 = eqn_to_block_tensor(fn1, xs1)\n",
    "cg2, og2, ot2, v2, t2 = eqn_to_block_tensor(fn2, xs2)\n",
    "\n",
    "const_guess = tf.concat([cg1, cg2], axis=0)\n",
    "values = tf.concat([v1, v2], axis=0)\n",
    "operand_guess = tf.concat([og1, og2], axis=0)\n",
    "operator_guess = tf.concat([ot1, ot2], axis=0)\n",
    "target = tf.concat([t1, t2], axis=0)\n",
    "\n",
    "operands = resolve_values(const_guess, values, operand_guess)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(operands)\n",
    "    tape.watch(operator_guess)\n",
    "    result = eager_process_block(operands, operator_guess)\n",
    "\n",
    "print_idx = 0\n",
    "tf.print(pretty_print_guess_tensor(const_guess[print_idx], operand_guess[print_idx], operator_guess[print_idx]))\n",
    "x_0, x_1 = 1, 2\n",
    "tf.print((((x_0 + x_1) + (x_0 - x_1)) + ((x_0 * x_1) - (x_0 / x_1))))\n",
    "tf.print(result)\n",
    "# tf.print(tf.reshape(tape.gradient(result, operands),(2,4)))\n",
    "tf.print(tape.gradient(result, operator_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(((x_0 + x_1) + (x_0 - x_1)) + ((x_0 * x_1) - (x_0 / x_1)))\n3.5\n[[[3.5]\n  [9.33333397]\n  [27.2]]\n\n [[3.5]\n  [9.33333397]\n  [27.2]]]\n[[[[-1 3 1 3]\n   [3 -3 3 3]\n   [1 3 1 1]\n   [3 3 1 -1]]\n\n  [[-3 3 3 3]\n   [3 1 -1 3]\n   [0 0 0 0]\n   [0 0 0 0]]\n\n  [[-1 3 1 3]\n   [0 0 0 0]\n   [0 0 0 0]\n   [0 0 0 0]]]\n\n\n [[[-1 3 1 3]\n   [3 -3 3 3]\n   [1 3 1 1]\n   [3 3 1 -1]]\n\n  [[-3 3 3 3]\n   [3 1 -1 3]\n   [0 0 0 0]\n   [0 0 0 0]]\n\n  [[-1 3 1 3]\n   [0 0 0 0]\n   [0 0 0 0]\n   [0 0 0 0]]]]\n"
    }
   ],
   "source": [
    "@tf.function\n",
    "def unrolled_process_block(operands, operators_arr, levels):\n",
    "    acc = operands\n",
    "    num_operands = 2 ** levels \n",
    "\n",
    "    for level in range(levels):\n",
    "        num_operands //= 2\n",
    "        op = operators_arr[:, level, :num_operands, :]\n",
    "        acc = operate(acc, op)\n",
    "\n",
    "    return acc\n",
    "\n",
    "fn1 = lambda x, y: x + y\n",
    "fn2 = lambda x, y: x - y\n",
    "xs1 = np.array([[1,2], [2,3], [4,5]], dtype=np.float32)\n",
    "xs2 = np.array([[1,2], [2,3], [4,5]], dtype=np.float32)\n",
    "\n",
    "cg1, og1, ot1, v1, t1 = eqn_to_block_tensor(fn1, xs1)\n",
    "cg2, og2, ot2, v2, t2 = eqn_to_block_tensor(fn2, xs2)\n",
    "\n",
    "const_guess = tf.concat([cg1, cg2], axis=0)\n",
    "values = tf.concat([v1, v2], axis=0)\n",
    "operand_guess = tf.concat([og1, og2], axis=0)\n",
    "operator_guess = tf.concat([ot1, ot2], axis=0)\n",
    "target = tf.concat([t1, t2], axis=0)\n",
    "\n",
    "operands = resolve_values(const_guess, values, operand_guess)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(operands)\n",
    "    tape.watch(operator_guess)\n",
    "    result = unrolled_process_block(operands, operator_guess, 3)\n",
    "\n",
    "print_idx = 0\n",
    "tf.print(pretty_print_guess_tensor(const_guess[print_idx], operand_guess[print_idx], operator_guess[print_idx]))\n",
    "x_0, x_1 = 1, 2\n",
    "tf.print((((x_0 + x_1) + (x_0 - x_1)) + ((x_0 * x_1) - (x_0 / x_1))))\n",
    "tf.print(result)\n",
    "# tf.print(tf.reshape(tape.gradient(result, operands),(2,4)))\n",
    "tf.print(tape.gradient(result, operator_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[[3.5]\n  [9.33333397]\n  [27.2]]\n\n [[3.5]\n  [9.33333397]\n  [27.2]]]\n636.267822\n[[[-23.0333347 23.0333347]\n  [-23.0333347 23.0333347]\n  [-23.0333347 23.0333347]\n  ...\n  [-81.9666748 81.9666748]\n  [4.834445 -4.834445]\n  [-3.74996305 3.74996305]]\n\n [[-43.0333328 43.0333328]\n  [-43.0333328 43.0333328]\n  [-43.0333328 43.0333328]\n  ...\n  [-137.966675 137.966675]\n  [11.334445 -11.334445]\n  [-7.9332962 7.9332962]]]\n[[[[22.0333347 -13.3666668 23.0333347 14.3666668]\n   [23.0333347 -23.0333347 23.0333347 23.0333347]\n   [23.0333347 23.0333347 22.0333347 -22.0333347]\n   [14.3666668 23.0333347 -13.3666668 22.0333347]]\n\n  [[13.3666668 23.0333347 -13.3666668 23.0333347]\n   [23.0333347 23.0333347 -23.0333347 23.0333347]\n   [0 0 0 0]\n   [0 0 0 0]]\n\n  [[23.0333347 23.0333347 22.0333347 -22.0333347]\n   [0 0 0 0]\n   [0 0 0 0]\n   [0 0 0 0]]]\n\n\n [[[43.0333328 -43.0333328 43.0333328 43.0333328]\n   [43.0333328 -43.0333328 43.0333328 43.0333328]\n   [43.0333328 -43.0333328 43.0333328 43.0333328]\n   [34.0333328 43.0333328 -34.0333328 43.0333328]]\n\n  [[43.0333328 43.0333328 -43.0333328 43.0333328]\n   [43.0333328 43.0333328 -43.0333328 43.0333328]\n   [0 0 0 0]\n   [0 0 0 0]]\n\n  [[43.0333328 13.3666668 43.0333328 -13.3666668]\n   [0 0 0 0]\n   [0 0 0 0]\n   [0 0 0 0]]]]\n"
    }
   ],
   "source": [
    "def bind_opt_train_step(opt, levels, entropy_weight=1e+2):\n",
    "    @tf.function\n",
    "    def train_step(const_guess, operand_guess, operator_guess, values, target):\n",
    "        with tf.GradientTape() as tape:\n",
    "            cg, opg, otg = const_guess, operand_guess, operator_guess\n",
    "\n",
    "            # cg = to_prob_dist_all(cg)\n",
    "            # opg = to_prob_dist_all(opg)\n",
    "            # otg = to_prob_dist_all(otg)\n",
    "\n",
    "            # cg_entropy = 0.0 # TODO\n",
    "            # opg_entropy = tf.reduce_sum(entropy(opg))\n",
    "            # otg_entropy = tf.reduce_sum(entropy(otg))\n",
    "\n",
    "            operands = resolve_values(cg, values, opg)\n",
    "            result = unrolled_process_block(operands, otg, levels)\n",
    "\n",
    "            target_loss = tf.nn.l2_loss(result - target)\n",
    "\n",
    "            loss = target_loss\n",
    "\n",
    "            # if target_loss < 1:\n",
    "            #     loss += entropy_weight * (opg_entropy + otg_entropy)\n",
    "\n",
    "        variables = [operand_guess, operator_guess]\n",
    "        grads = tape.gradient(loss, variables)\n",
    "        # grads = [tf.clip_by_norm(g, 100.0) for g in grads]\n",
    "        opt.apply_gradients(zip(grads, variables))\n",
    "\n",
    "        # const_guess.assign(to_prob_dist_all(const_guess))\n",
    "        operand_guess.assign(to_prob_dist_all(operand_guess))\n",
    "        operator_guess.assign(to_prob_dist_all(operator_guess))\n",
    "\n",
    "        return loss, result\n",
    "\n",
    "    return train_step\n",
    "\n",
    "fn1 = lambda x, y: x + y\n",
    "fn2 = lambda x, y: x - y\n",
    "xs1 = np.array([[1,2], [2,3], [4,5]], dtype=np.float32)\n",
    "xs2 = np.array([[1,2], [2,3], [4,5]], dtype=np.float32)\n",
    "\n",
    "cg1, og1, ot1, v1, t1 = eqn_to_block_tensor(fn1, xs1)\n",
    "cg2, og2, ot2, v2, t2 = eqn_to_block_tensor(fn2, xs2)\n",
    "\n",
    "const_guess = tf.concat([cg1, cg2], axis=0)\n",
    "values = tf.concat([v1, v2], axis=0)\n",
    "operand_guess = tf.concat([og1, og2], axis=0)\n",
    "operator_guess = tf.concat([ot1, ot2], axis=0)\n",
    "target = tf.concat([t1, t2], axis=0)\n",
    "levels = 3\n",
    "\n",
    "operand_guess = tf.Variable(operand_guess)\n",
    "operator_guess = tf.Variable(operator_guess)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=1e-1,\n",
    "    staircase=True)\n",
    "opt = tf.keras.optimizers.Adam(lr_schedule)\n",
    "train_step = bind_opt_train_step(opt, levels)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    # tape.watch(const_guess)\n",
    "    tape.watch(operand_guess)\n",
    "    tape.watch(operator_guess)\n",
    "\n",
    "    loss, result = train_step(const_guess, operand_guess, operator_guess, values, target)\n",
    "\n",
    "tf.print(result)\n",
    "tf.print(loss)\n",
    "tf.print(tape.gradient(loss, operand_guess))\n",
    "tf.print(tape.gradient(loss, operator_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "59 ((x_0 + x_1) + (x_0 - x_1)) ((x_0 + x_1) + (x_0 - x_1))\n1.5 ((x_1 + x_1) + (x_1 - x_1)) ((x_0 / x_0) * (x_0 - x_1))\n1.5 ((x_0 + x_1) + (x_0 - x_1)) ((x_0 / x_0) * (x_0 - x_1))\n1.5 ((x_1 + x_1) + (x_1 - x_1)) ((x_0 / x_0) * (x_0 - x_1))\n0 ((x_1 + x_1) + (x_0 - x_1)) ((x_0 / x_0) * (x_0 - x_1))\n0 ((x_1 + x_1) + (x_0 - x_1)) ((x_0 / x_0) * (x_0 - x_1))\n0 ((x_1 + x_1) + (x_0 - x_1)) ((x_0 / x_0) * (x_0 - x_1))\n0 ((x_1 + x_1) + (x_0 - x_1)) ((x_0 / x_0) * (x_0 - x_1))\n0 ((x_1 + x_1) + (x_0 - x_1)) ((x_0 / x_0) * (x_0 - x_1))\n0 ((x_1 + x_1) + (x_0 - x_1)) ((x_0 / x_0) * (x_0 - x_1))\n[[3 5 9]\n [-1 -1 -1]]\n[[3 5 9]\n [-1 -1 -1]]\n"
    }
   ],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-1,\n",
    "    decay_steps=100,\n",
    "    decay_rate=1e-1,\n",
    "    staircase=True)\n",
    "opt = tf.keras.optimizers.Adam(lr_schedule)\n",
    "\n",
    "fn1 = lambda x, y: x + y\n",
    "fn2 = lambda x, y: x - y\n",
    "xs1 = np.array([[1,2], [2,3], [4,5]], dtype=np.float32)\n",
    "xs2 = np.array([[1,2], [2,3], [4,5]], dtype=np.float32)\n",
    "\n",
    "levels = 2\n",
    "\n",
    "cg1, og1, ot1, v1, t1 = eqn_to_block_tensor(fn1, xs1, levels)\n",
    "cg2, og2, ot2, v2, t2 = eqn_to_block_tensor(fn2, xs2, levels)\n",
    "\n",
    "const_guess = tf.concat([cg1, cg2], axis=0)\n",
    "values = tf.concat([v1, v2], axis=0)\n",
    "operand_guess = tf.concat([og1, og2], axis=0)\n",
    "operator_guess = tf.concat([ot1, ot2], axis=0)\n",
    "target = tf.concat([t1, t2], axis=0)\n",
    "# const_guess, values, operand_guess, operator_guess, target = cg1, v1, og1, ot1, t1\n",
    "# const_guess, values, operand_guess, operator_guess, target = cg2, v2, og2, ot2, t2\n",
    "\n",
    "operand_guess = tf.Variable(operand_guess)\n",
    "operator_guess = tf.Variable(operator_guess)\n",
    "\n",
    "train_step = bind_opt_train_step(opt, levels)\n",
    "\n",
    "steps = 100\n",
    "for i in range(steps):\n",
    "    loss, result = train_step(const_guess, operand_guess, operator_guess, values, target)\n",
    "\n",
    "    if i % (steps // 10) == 0:\n",
    "        print_row = lambda x: pretty_print_guess_tensor(const_guess[x], operand_guess[x], operator_guess[x])\n",
    "        tf.print(loss, print_row(0), print_row(1))\n",
    "\n",
    "tf.print(tf.squeeze(result))\n",
    "tf.print(tf.squeeze(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 4, 2), dtype=float32, numpy=\narray([[[ 40.,  60.],\n        [ 16.,  84.],\n        [ 66.,  34.],\n        [  0., 100.]],\n\n       [[100.,   0.],\n        [100.,   0.],\n        [100.,   0.],\n        [  2.,  98.]]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "tf.round(operand_guess * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 2, 4), dtype=float32, numpy=\narray([[[[100.,   0.,   0.,   0.],\n         [  0., 100.,   0.,   0.]],\n\n        [[100.,   0.,   0.,   0.],\n         [  0., 100.,   0.,   0.]]],\n\n\n       [[[ 24.,   0.,   0.,  76.],\n         [  0., 100.,   0.,   0.]],\n\n        [[  0.,   0., 100.,   0.],\n         [  0., 100.,   0.,   0.]]]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "tf.round(operator_guess * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}